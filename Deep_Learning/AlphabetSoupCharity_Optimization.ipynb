{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 14:46:10.618187: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-25 14:46:12.104813: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-25 14:46:12.110004: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# Display all of the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(['EIN','NAME'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "# application_info = application_df.columns.values.tolist()\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "at_vc = application_df['APPLICATION_TYPE'].value_counts()\n",
    "at_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = at_vc[at_vc < 500].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T9', 'T13', 'T12', 'T2', 'T25', 'T14', 'T29', 'T15', 'T17']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_types_to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "c_vc= application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C1720        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1267        2\n",
       "C1256        2\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "c_vc[c_vc > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = c_vc[c_vc < 1000].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_df_d = pd.get_dummies(application_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                       0   \n",
       "1           1    108590              1                       0   \n",
       "2           1      5000              0                       0   \n",
       "3           1      6692              1                       0   \n",
       "4           1    142590              1                       0   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                       0   \n",
       "34295       1      5000              0                       0   \n",
       "34296       1      5000              0                       0   \n",
       "34297       1      5000              1                       0   \n",
       "34298       1  36500179              0                       0   \n",
       "\n",
       "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                         1                     0                    0   \n",
       "1                         0                     0                    1   \n",
       "2                         0                     0                    0   \n",
       "3                         0                     0                    1   \n",
       "4                         0                     0                    1   \n",
       "...                     ...                   ...                  ...   \n",
       "34294                     0                     0                    0   \n",
       "34295                     0                     0                    0   \n",
       "34296                     0                     0                    1   \n",
       "34297                     0                     0                    0   \n",
       "34298                     0                     0                    1   \n",
       "\n",
       "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  \\\n",
       "0                        0                    0                    0   \n",
       "1                        0                    0                    0   \n",
       "2                        0                    1                    0   \n",
       "3                        0                    0                    0   \n",
       "4                        0                    0                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "34294                    1                    0                    0   \n",
       "34295                    1                    0                    0   \n",
       "34296                    0                    0                    0   \n",
       "34297                    0                    1                    0   \n",
       "34298                    0                    0                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  AFFILIATION_CompanySponsored  \\\n",
       "0                        0                    0                             0   \n",
       "1                        0                    0                             0   \n",
       "2                        0                    0                             1   \n",
       "3                        0                    0                             1   \n",
       "4                        0                    0                             0   \n",
       "...                    ...                  ...                           ...   \n",
       "34294                    0                    0                             0   \n",
       "34295                    0                    0                             1   \n",
       "34296                    0                    0                             1   \n",
       "34297                    0                    0                             0   \n",
       "34298                    0                    0                             0   \n",
       "\n",
       "       AFFILIATION_Family/Parent  AFFILIATION_Independent  \\\n",
       "0                              0                        1   \n",
       "1                              0                        1   \n",
       "2                              0                        0   \n",
       "3                              0                        0   \n",
       "4                              0                        1   \n",
       "...                          ...                      ...   \n",
       "34294                          0                        1   \n",
       "34295                          0                        0   \n",
       "34296                          0                        0   \n",
       "34297                          0                        1   \n",
       "34298                          0                        1   \n",
       "\n",
       "       AFFILIATION_National  AFFILIATION_Other  AFFILIATION_Regional  \\\n",
       "0                         0                  0                     0   \n",
       "1                         0                  0                     0   \n",
       "2                         0                  0                     0   \n",
       "3                         0                  0                     0   \n",
       "4                         0                  0                     0   \n",
       "...                     ...                ...                   ...   \n",
       "34294                     0                  0                     0   \n",
       "34295                     0                  0                     0   \n",
       "34296                     0                  0                     0   \n",
       "34297                     0                  0                     0   \n",
       "34298                     0                  0                     0   \n",
       "\n",
       "       CLASSIFICATION_C1000  CLASSIFICATION_C1200  CLASSIFICATION_C2000  \\\n",
       "0                         1                     0                     0   \n",
       "1                         0                     0                     1   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     1   \n",
       "4                         1                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "34294                     1                     0                     0   \n",
       "34295                     0                     0                     0   \n",
       "34296                     0                     0                     1   \n",
       "34297                     0                     0                     0   \n",
       "34298                     1                     0                     0   \n",
       "\n",
       "       CLASSIFICATION_C2100  CLASSIFICATION_C3000  CLASSIFICATION_Other  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     1                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "34294                     0                     0                     0   \n",
       "34295                     0                     1                     0   \n",
       "34296                     0                     0                     0   \n",
       "34297                     0                     1                     0   \n",
       "34298                     0                     0                     0   \n",
       "\n",
       "       USE_CASE_CommunityServ  USE_CASE_Heathcare  USE_CASE_Other  \\\n",
       "0                           0                   0               0   \n",
       "1                           0                   0               0   \n",
       "2                           0                   0               0   \n",
       "3                           0                   0               0   \n",
       "4                           0                   1               0   \n",
       "...                       ...                 ...             ...   \n",
       "34294                       0                   0               0   \n",
       "34295                       0                   0               0   \n",
       "34296                       0                   0               0   \n",
       "34297                       0                   0               0   \n",
       "34298                       0                   0               0   \n",
       "\n",
       "       USE_CASE_Preservation  USE_CASE_ProductDev  ORGANIZATION_Association  \\\n",
       "0                          0                    1                         1   \n",
       "1                          1                    0                         0   \n",
       "2                          0                    1                         1   \n",
       "3                          1                    0                         0   \n",
       "4                          0                    0                         0   \n",
       "...                      ...                  ...                       ...   \n",
       "34294                      0                    1                         1   \n",
       "34295                      0                    1                         1   \n",
       "34296                      1                    0                         1   \n",
       "34297                      0                    1                         1   \n",
       "34298                      1                    0                         0   \n",
       "\n",
       "       ORGANIZATION_Co-operative  ORGANIZATION_Corporation  \\\n",
       "0                              0                         0   \n",
       "1                              1                         0   \n",
       "2                              0                         0   \n",
       "3                              0                         0   \n",
       "4                              0                         0   \n",
       "...                          ...                       ...   \n",
       "34294                          0                         0   \n",
       "34295                          0                         0   \n",
       "34296                          0                         0   \n",
       "34297                          0                         0   \n",
       "34298                          1                         0   \n",
       "\n",
       "       ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
       "0                       0             1                  0   \n",
       "1                       0             0                  1   \n",
       "2                       0             1                  0   \n",
       "3                       1             0                  0   \n",
       "4                       1             0                  0   \n",
       "...                   ...           ...                ...   \n",
       "34294                   0             1                  0   \n",
       "34295                   0             1                  0   \n",
       "34296                   0             1                  0   \n",
       "34297                   0             1                  0   \n",
       "34298                   0             0                  0   \n",
       "\n",
       "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                           0                         0                   0   \n",
       "1                           0                         0                   0   \n",
       "2                           0                         0                   0   \n",
       "3                           1                         0                   0   \n",
       "4                           0                         1                   0   \n",
       "...                       ...                       ...                 ...   \n",
       "34294                       0                         0                   0   \n",
       "34295                       0                         0                   0   \n",
       "34296                       0                         0                   0   \n",
       "34297                       0                         0                   0   \n",
       "34298                       0                         0                   0   \n",
       "\n",
       "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0                     0                       0                0   \n",
       "1                     0                       0                0   \n",
       "2                     0                       0                0   \n",
       "3                     0                       0                0   \n",
       "4                     0                       0                0   \n",
       "...                 ...                     ...              ...   \n",
       "34294                 0                       0                0   \n",
       "34295                 0                       0                0   \n",
       "34296                 0                       0                0   \n",
       "34297                 0                       0                0   \n",
       "34298                 1                       0                0   \n",
       "\n",
       "       INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                      0                         1                         0  \n",
       "1                      0                         1                         0  \n",
       "2                      0                         1                         0  \n",
       "3                      0                         1                         0  \n",
       "4                      0                         1                         0  \n",
       "...                  ...                       ...                       ...  \n",
       "34294                  0                         1                         0  \n",
       "34295                  0                         1                         0  \n",
       "34296                  0                         1                         0  \n",
       "34297                  0                         1                         0  \n",
       "34298                  0                         1                         0  \n",
       "\n",
       "[34299 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df_d[\"IS_SUCCESSFUL\"].values\n",
    "X = application_df_d.drop([\"IS_SUCCESSFUL\", 'SPECIAL_CONSIDERATIONS_Y'],axis=1).values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_61 (Dense)            (None, 512)               22016     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,449\n",
      "Trainable params: 198,529\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 512\n",
    "hidden_nodes_layer2 = 512//2\n",
    "hidden_nodes_layer3 = 512//4\n",
    "hidden_nodes_layer4 = 512//8\n",
    "hidden_nodes_layer5 = 512//16\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "nn.add(tf.keras.layers.BatchNormalization())\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "nn.add(tf.keras.layers.BatchNormalization())\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation='relu'))\n",
    "nn.add(tf.keras.layers.BatchNormalization())\n",
    "# hidden layer 4\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation='relu'))\n",
    "nn.add(tf.keras.layers.BatchNormalization())\n",
    "# hidden layer 5\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\"))\n",
    "\n",
    "# Output layer\"\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(756, activation='relu', input_shape=X_train_scaled[0].shape),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dense(756//2, activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dense(756//4, activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dense(756//8, activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dense(756//10, activation='relu'),   \n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add halt training method to reduce unneeded epochs based on loss plateau https://stackoverflow.com/questions/66530274/tricks-to-improve-cnn-model-performance\n",
    "es=tf.keras.callbacks.EarlyStopping( monitor=\"val_loss\", patience=10,\n",
    "                                     verbose=1,  restore_best_weights=True)\n",
    "rlronp=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=1,\n",
    "                                             verbose=1)\n",
    "callbacks=[es, rlronp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 14s 15ms/step - loss: 0.5787 - accuracy: 0.7183 - val_loss: 0.5629 - val_accuracy: 0.7234 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 14s 17ms/step - loss: 0.5632 - accuracy: 0.7239 - val_loss: 0.5589 - val_accuracy: 0.7276 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 13s 16ms/step - loss: 0.5608 - accuracy: 0.7247 - val_loss: 0.5560 - val_accuracy: 0.7294 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "802/804 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.7282\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "804/804 [==============================] - 10s 13ms/step - loss: 0.5575 - accuracy: 0.7281 - val_loss: 0.5574 - val_accuracy: 0.7315 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 12s 14ms/step - loss: 0.5512 - accuracy: 0.7294 - val_loss: 0.5535 - val_accuracy: 0.7319 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5497 - accuracy: 0.7308 - val_loss: 0.5515 - val_accuracy: 0.7338 - lr: 3.0000e-04\n",
      "Epoch 7/100\n",
      "802/804 [============================>.] - ETA: 0s - loss: 0.5496 - accuracy: 0.7316\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5494 - accuracy: 0.7317 - val_loss: 0.5529 - val_accuracy: 0.7339 - lr: 3.0000e-04\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5454 - accuracy: 0.7327 - val_loss: 0.5508 - val_accuracy: 0.7342 - lr: 9.0000e-05\n",
      "Epoch 9/100\n",
      "802/804 [============================>.] - ETA: 0s - loss: 0.5454 - accuracy: 0.7325\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "804/804 [==============================] - 13s 16ms/step - loss: 0.5453 - accuracy: 0.7327 - val_loss: 0.5513 - val_accuracy: 0.7334 - lr: 9.0000e-05\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5441 - accuracy: 0.7337 - val_loss: 0.5501 - val_accuracy: 0.7340 - lr: 2.7000e-05\n",
      "Epoch 11/100\n",
      "803/804 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.7324\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5439 - accuracy: 0.7325 - val_loss: 0.5503 - val_accuracy: 0.7336 - lr: 2.7000e-05\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.7341\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5424 - accuracy: 0.7341 - val_loss: 0.5501 - val_accuracy: 0.7338 - lr: 8.1000e-06\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.7343\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
      "804/804 [==============================] - 12s 14ms/step - loss: 0.5422 - accuracy: 0.7343 - val_loss: 0.5504 - val_accuracy: 0.7335 - lr: 2.4300e-06\n",
      "Epoch 14/100\n",
      "803/804 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.7362\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
      "804/804 [==============================] - 12s 14ms/step - loss: 0.5425 - accuracy: 0.7360 - val_loss: 0.5501 - val_accuracy: 0.7336 - lr: 7.2900e-07\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.7351\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
      "804/804 [==============================] - 13s 17ms/step - loss: 0.5432 - accuracy: 0.7351 - val_loss: 0.5505 - val_accuracy: 0.7338 - lr: 2.1870e-07\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 13s 16ms/step - loss: 0.5428 - accuracy: 0.7334 - val_loss: 0.5500 - val_accuracy: 0.7336 - lr: 6.5610e-08\n",
      "Epoch 17/100\n",
      "803/804 [============================>.] - ETA: 0s - loss: 0.5429 - accuracy: 0.7342\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
      "804/804 [==============================] - 13s 16ms/step - loss: 0.5428 - accuracy: 0.7343 - val_loss: 0.5505 - val_accuracy: 0.7339 - lr: 6.5610e-08\n",
      "Epoch 18/100\n",
      "802/804 [============================>.] - ETA: 0s - loss: 0.5420 - accuracy: 0.7353\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 5.904900035602622e-09.\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5418 - accuracy: 0.7355 - val_loss: 0.5504 - val_accuracy: 0.7338 - lr: 1.9683e-08\n",
      "Epoch 19/100\n",
      "802/804 [============================>.] - ETA: 0s - loss: 0.5428 - accuracy: 0.7353\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.7714700373261393e-09.\n",
      "804/804 [==============================] - 13s 17ms/step - loss: 0.5428 - accuracy: 0.7352 - val_loss: 0.5504 - val_accuracy: 0.7339 - lr: 5.9049e-09\n",
      "Epoch 20/100\n",
      "803/804 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.7347\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 5.314410245205181e-10.\n",
      "804/804 [==============================] - 13s 16ms/step - loss: 0.5422 - accuracy: 0.7348 - val_loss: 0.5502 - val_accuracy: 0.7339 - lr: 1.7715e-09\n",
      "Epoch 21/100\n",
      "801/804 [============================>.] - ETA: 0s - loss: 0.5427 - accuracy: 0.7348\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5943230069481729e-10.\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5429 - accuracy: 0.7346 - val_loss: 0.5505 - val_accuracy: 0.7339 - lr: 5.3144e-10\n",
      "Epoch 22/100\n",
      "802/804 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.7353\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.7829690208445185e-11.\n",
      "804/804 [==============================] - 13s 16ms/step - loss: 0.5425 - accuracy: 0.7352 - val_loss: 0.5501 - val_accuracy: 0.7340 - lr: 1.5943e-10\n",
      "Epoch 23/100\n",
      "800/804 [============================>.] - ETA: 0s - loss: 0.5432 - accuracy: 0.7346\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.434890747886719e-11.\n",
      "804/804 [==============================] - 13s 16ms/step - loss: 0.5433 - accuracy: 0.7348 - val_loss: 0.5504 - val_accuracy: 0.7339 - lr: 4.7830e-11\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.7345\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.304672243660157e-12.\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5428 - accuracy: 0.7345 - val_loss: 0.5505 - val_accuracy: 0.7338 - lr: 1.4349e-11\n",
      "Epoch 25/100\n",
      "801/804 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.7347\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.2914016210563428e-12.\n",
      "804/804 [==============================] - 13s 17ms/step - loss: 0.5428 - accuracy: 0.7345 - val_loss: 0.5505 - val_accuracy: 0.7339 - lr: 4.3047e-12\n",
      "Epoch 26/100\n",
      "803/804 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.7347Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.874204993273289e-13.\n",
      "804/804 [==============================] - 12s 15ms/step - loss: 0.5425 - accuracy: 0.7347 - val_loss: 0.5502 - val_accuracy: 0.7335 - lr: 1.2914e-12\n",
      "Epoch 26: early stopping\n",
      "268/268 - 1s - loss: 0.5500 - accuracy: 0.7336 - 728ms/epoch - 3ms/step\n",
      "Loss: 0.5499716401100159, Accuracy: 0.7336443066596985\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=callbacks, validation_data=(X_test_scaled,y_test))\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the model history \n",
    "plt.style.use('ggplot')\n",
    "plt.plot(fit_model.history['accuracy'], label = 'acc')\n",
    "plt.plot(fit_model.history['val_accuracy'], label='val acc')\n",
    "plt.title(\"accuracy vs validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_Optimization2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.20%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 352       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403\n",
      "Trainable params: 403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model0 = load_model('AlphabetSoupCharity.h5')\n",
    "X = application_df_d.drop([\"IS_SUCCESSFUL\"],axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=58)\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "score = model0.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print (\"%s: %.2f%%\" % (model0.metrics_names[1], score[1]*100))\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.78%\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_126 (Dense)           (None, 512)               22016     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,449\n",
      "Trainable params: 198,529\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model('AlphabetSoupCharity_Optimization1.h5')\n",
    "X = application_df_d.drop([\"IS_SUCCESSFUL\", 'SPECIAL_CONSIDERATIONS_Y'],axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=58)\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "score = model1.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print (\"%s: %.2f%%\" % (model1.metrics_names[1], score[1]*100))\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.26%\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 1024)              44032     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 102)               13158     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 103       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 746,317\n",
      "Trainable params: 746,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = load_model('AlphabetSoupCharity_Optimization2.h5')\n",
    "\n",
    "score = model2.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print (\"%s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.714868804664723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=58)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=100)\n",
    "forest.fit(X_train,y_train)\n",
    "predictions = forest.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
